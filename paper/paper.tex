\documentclass[conference]{IEEEtran}

\usepackage[fleqn]{amsmath}
\usepackage{algpseudocode}
\usepackage{graphicx}
\graphicspath{{./images/}}
\interdisplaylinepenalty=2500
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
\title{Parallel Bat Optimization on GPU using CUDA}

\author{\IEEEauthorblockN{Jean Carlo Machado}
\IEEEauthorblockA{Univerisdade do Estado de Santa Catarina\\Mestrado de Computação Aplicada\\
UDESC\\
Santa Catarina, Joinville,\\
Email: contato@jeancarlomachado.com.br}
\and
\IEEEauthorblockN{Rafael Stubs Parpinelli}
\IEEEauthorblockA{Univerisdade do Estado de Santa Catarina\\ UDESC\\
Santa Catarina, Joinville
}}

\maketitle
\begin{abstract}
The ever increasing parallel processing power of GPU's is an compelling
motive to implement performance demanding algorithms, like optimization
techniques, using this approach. This work aimed to develop a GPU
version of the bat metaheuristic, a CPU version were developed as well,
as a way of comparison. A set of experiments where conducted in order
to measure the speedup difference. The results suggests that the GPU
version is able to achieve relevant speedups in highly populational
problems but for simpler cases the CPU version might outperform GPU.
\end{abstract}
\IEEEpeerreviewmaketitle

\section{Introduction}

The bat algorithm is a populational meta-heuristic introduced by Yang in
2010. It uses the inspiration of micro-bats which uses a type of sonar,
called echolocation, to detect prey, avoid obstacles, and locate their
roosting crevices in the dark \cite{original}.

All populational meta-heuristics theoretically are able to benefit from
implicit parallelization, which is the approach that each individual of
the population executes concurrently.

Compute unified device architecture (CUDA) is a platform to execute
software concurrently, It uses a single data multiple execution
approach. Previous researches suggests that highly parallel
general processing application, speedups may vary from 10 to 450
\cite{cuda_optimizations}.

This work attempts to investigate the applicability of the BAT algorithm
concurrently on the GPU. Previously some demonstrations of the bat
algorithm parallelized on CPU were presented in \cite{paralellCPUFirst}
and \cite{paralellCPU}, however, til the day of this publication no
implementation of the bat algorithm was found for GPU. 

\section{The CUDA platform}

The CUDA platform uses a parallelization schema in "each cuda
device supports the Single-Program Multiple-Data (SPMD)"
\cite{cuda_optimizations}, where all concurrent threads are based on the
same code but they may follow different paths.

A good approach is to use the threaded model since it has the great benefit in performance.

"..when attempting to achieve an application's maximum
performance, the primary concern often is managing global memory
latency." \cite{cuda_optimizations}

\section{Bat Design on CPU}

The bat original paper don't clarify  all the implementation details working of the algoritm.

In this work the bath algorithm used was the one proposed by
\autocite{Jelson et al.}, since it represents a concrete demonstration of how
the bat metaheuristic might work.

Some distinctions of the original paper are worth noticing

\begin{itemize}
    \item The selection of new results on the original paper tends to be more greedy (line 14) [improve the descritpion of the other paper].
    \item On this paper the or operator were used but in the original one an And were proposed.
    \item The or operator tends to explore the search space better (more diversity).

    \item There's a distortion on a single dimension of the search space in
order to increase the diversity factor.
\end{itemize}

The CPU version developed was single threaded.
The random algorithm used was the Mersenne twister.

\begin{figure}
\begin{algorithmic}[1]
\State $Parameters:\ n,\alpha,\ \lambda$
\State $initialize\ bats$
\State $evaluate\ fitness$
\State $selects\ best$
\While {$stop\ criteria\ false$}
    \For{$each\ bat$}

        \State $f_i=f_{min} + (f_{max} - f_{min})\beta, \in \beta [0,1]$
        \State $\vec{v}_i^{t+1} = \vec{v}_i^{t} + (\vec{x}_i^{t} + \vec{x}_*^{t})f_i$
        \State $\vec{x}_{temp} = \vec{x}_i^{t} + \vec{v}_i^{t+1}$
        \If {$rand < r_i, rand \in [0,1] $}
            \State $\vec{x}_{temp} = \vec{x}_* + \epsilon A_m, \epsilon \in [-1, 1]$
        \EndIf

        \State $single\ dimension\ perturbation\ in\ x_{temp}$
        \If {$a < A_i^t\ \textbf{or}\ f(\vec{x}_{temp}) \leq f(\vec{x}_i), a \in [0,1] $}
            \State $\vec{x}_i^t = \vec{x}_{temp}$
            \State $r_i = exp(\lambda * i)$
            \State $A_i =  A_{0} * \alpha^i$
        \EndIf
        \State $selects\ best$
    \EndFor
\EndWhile
\end{algorithmic}
\caption{Pseudo-code CPU}\label{GPU}
\end{figure}


\section{Bat Design on GPU}

\begin{figure}
    \includegraphics{activitydiagram}
    \caption{GPU process flow}
\end{figure}

Since the BAT algorithm uses a population of bats, the most intuitive
parallelization method to apply on it is to use each bat on each GPU
thread. \cite{pso-gpu} used a similar method for a GPU implementation
for the PSO algorithm.

In the bat algorithm synchronization must occur on the selection of the
best individual of the iteration. The best individual is kept in the
threaded memory of the GPU which has a limit of 16KB, probably not feasible for
more complex problems.

The random number generator used on the GPU was the MTGP32, to
maintain the compatibility with the CPU version. Notwithstanding
it's not recommended to use more than 256 threads per block with it
\cite{curandIssue}.


\begin{figure}
\begin{algorithmic}[1]
\State $Parameters:\ n,\alpha,\ \lambda$
\State $initialize\ bats\ asynchronously$
\State $evaluate\ fitness$
\State $synchronize\ threads$
\State $selects\ best$
\While {$stop\ criteria\ false$}
    \For{$each thread$}

        \State $f_i=f_{min} + (f_{max} - f_{min})\beta, \in \beta [0,1]$
        \State $\vec{v}_i^{t+1} = \vec{v}_i^{t} + (\vec{x}_i^{t} + \vec{x}_*^{t})f_i$
        \State $\vec{x}_{temp} = \vec{x}_i^{t} + \vec{v}_i^{t+1}$
        \If {$rand < r_i, rand \in [0,1] $}
            \State $\vec{x}_{temp} = \vec{x}_* + \epsilon A_m, \epsilon \in [-1, 1]$
        \EndIf

        \State $single\ dimension\ perturbation\ in\ x_{temp}$
        \If {$a < A_i^t\ \textbf{or}\ f(\vec{x}_{temp}) \leq f(\vec{x}_i), a \in [0,1] $}
            \State $\vec{x}_i^t = \vec{x}_{temp}$
            \State $r_i = exp(\lambda * i)$
            \State $A_i =  A_{0} * \alpha^i$
        \EndIf
        \State $synchronize\ threads$
        \State $selects\ best$
    \EndFor
\EndWhile
\end{algorithmic}
\caption{Pseudo-code GPU}\label{GPU}
\end{figure}

\section{Experiments}

For testing the performance of the algorithm a set of experiments where
developed using diverse benchmark functions tested against a set of
individuals in a highly dimensional problem.

The benchmark functions used were the following:

\begin{itemize}
    \item Ackley
    \item Griewank
    \item Rastringin
    \item Rosenbrook
\end{itemize}

The experiments were executed on a machine with the following configuration:

\textit{Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz \\ GK208 GeForce GT 720 1024 MB of vram}

Each experiment was executed a total of 20 times with 10 thousand
iterations each and 100 dimensions in each function.

\begin{table}[!htbp]
    \renewcommand{\arraystretch}{1.3}
    \caption{Experiments}
    \label{experiments}
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
        \bf Name & Function &  Dimensions & Agents\\
    \hline
        E1 & Ackley & 100 & 256\\
        E2 & Ackley & 100 & 768\\
        E3 & Griewank & 100 & 256\\
        E4 & Griewank & 100 & 768\\
        E5 & Rastringin & 100 & 256\\
        E6 & Rastringin & 100 & 768\\
        E7 & Rosenbrook & 100 & 256\\
        E8 & Rosenbrook & 100 & 768\\
    \end{tabular}
\end{table}

\section{Results}

In this section are described the speedup and convergence results. The
time spent in each execution of the algorithms is described in seconds.

\begin{table}[!t]
    \renewcommand{\arraystretch}{1.3}
    \caption{CPU Results}
    \label{results}
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
        Time Avg & Time SD & Fit Avg & Fit SD\\
    \hline
        (E1) 49.4428 & 0.0557314 & 4.44089e-16 & 2.05196e-22 \\
        (E2) 161.439 & 0.155131 & 4.44089e-16 & 2.82843e-22 \\
        (E3) 61.3661 & 5.06578   & 0  & 0 \\
        (E4) 162.761 & 57.8119 & 0 & 0 \\
        (E5) 52.0624 & 9.25666   & 0  & 0 \\
        (E6) 171.986 & 14.9089 & 0 & 0 \\
        (E7) 20.4486 & 0.0847218 & 98.9875 & 0.0405622 \\
        (E8) 74.3533 & 0.186482 & 98.9864 & 0.0204378 \\
    \end{tabular}
\end{table}

\begin{table}[!t]
    \renewcommand{\arraystretch}{1.3}
    \caption{GPU Results}
    \label{results}
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
        Time Avg & Time SD & Fit Avg & Fit SD\\
    \hline
        (E1) 17.2255  & 0.708198 &  12.8881 & 2.40027 \\
        (E2) 10.9591  & 0.23902 & 10.9412 & 3.23942 \\
        (E3) 24.2459  & 0.740923  & 2.04281e-15 & 2.60744e-16 \\
        (E4) 15.0012 & 2.01505e-15 & 2.55402e-16 & 0.0394986 \\
        (E5) 30.4483  & 2.0005    & 0 & 0 \\
        (E6) 14.4247 & 0.0543432 & 0 & 0 \\
        (E7) 28.9867 & 1.24554 & 105.03 & 31.2888 \\
        (E8) 15.4403 & 0.326284 & 101.793 & 140.393 \\
    \end{tabular}
\end{table}


The fitness of almost all functions presented a slight worse result when compared with the cpu version.
It seems that, the subsequent bats of the same iteration don't have a best based on this current iteration.

\section{Conclusion}

It was observed speedups with big populations. The original BAT was
proposed with 40 individuals and the speedups was seen with 250
individuals.

The advantages of the algorithm may be tested against a threaded CPU
implementation to be fair.

With this work it's clear that is possible to speedup the bat
metaheuristic using GPU. Notwithstanding the best results are only
achievable on really complex problems with many dimensions.

\section{Further works}

In the future it may be explored the usage of blocks as representation
for the dimensions in which each bat details.

A subpopulation approach may also work, considering each GPU block as
it's boundaries, somewhat similar to the work made on parallel bat on
CPU by \cite{paralellCPU}.


\begin{thebibliography}{1}
\bibitem{original}
    Xin-She Yang \emph{A New Metaheuristics Bat-Inspired Algorithm}. Department of Engineering, Cambridge, 2010.
\bibitem{Jelson et al.}
    Jelson A. Cordeiro, Rafael Stubs Parpinelli Heitor Silvério Lopes \emph{Análise de Sensibilidade dos Parâmetros do Bat Algorithm e Comparação de Desempenho}.
\bibitem{pso-gpu}
    PSO-GPU: Accelerating Particle Swarm Optimization in CUDA-Based Graphics Processing Unit
\bibitem{curandIssue}
    \url{http://docs.nvidia.com/cuda/curand/device-api-overview.html#device-api-overview}
\bibitem{paralellCPU}
    Parallelized Bat Algorithm with a Communication Strategy. Cheng-Fu Tsai, Thin-Kien Dao, Wei-Jie Yang, et al, University of applied sciences
\bibitem{paralellCPUFirst}
    Parallel bat algorithm for optimizing makespan in job scheduling problems, Thi-Kien Dao, Tien-Szu Pan, Trong-The Nguyen, Jeng-Shyang Pan,2015, Springer Sience Review
\bibitem{gpuOptimization}
    Optimization Principles and Application Performance Evaluation of a Multithreaded GPU using Cuda, Shane Ryo
\bibitem{cuda_optimizations}
    Optimization Principles and Application Performance Evaluation on a Multithreaded GPU using CUDA, Shane Ryoo, Critopher I Rodrigues et all

\end{thebibliography}
\end{document}
