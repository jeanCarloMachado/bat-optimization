\documentclass[conference]{IEEEtran}

\usepackage[fleqn]{amsmath}
\usepackage{algpseudocode}
\interdisplaylinepenalty=2500
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
\title{Bat Optimization on GPU}

\author{\IEEEauthorblockN{Jean Carlo Machado}
\IEEEauthorblockA{Univerisdade do Estado de Santa Catarina\\Mestrado de Computação Aplicada\\
UDESC\\
Santa Catarina, Joinville,\\
Email: contato@jeancarlomachado.com.br}}

\maketitle
\begin{abstract}
This work developed a CPU implementation and a GPU one. And a set of
experiments where made in order to measure the speedup. The research
shows that the GPU version is able to achieve relevant speedups in
highly populational problems.
\end{abstract}
\IEEEpeerreviewmaketitle

\section{Introduction}

The bat algorithm is a populational meta-heuristic introduced by Yang in
2010. It uses the inspiration of micro-bats which uses a type of sonar,
called echolocation, to detect prey, avoid obstacles, and locate their
roosting crevices in the dark \cite{original}.

All populational meta-heuristic theoretically can benefit from implicit
parallelization, which is the approach that each individual of the
populations executes concurrently.

This work attempts to investigate the applicability of the BAT algorithm
concurrently on the GPU. Previously some demonstrations of the bat
algorithm parallelized on CPU were presented in \cite{paralellCPUFirst}
and \cite{paralellCPU}, however, til the day of this publication no
implementation of the bat algorithm was found on GPU. The GPU is a
great place to run populational algorithms because GPUs are able to
parallelize high loads of concurrent individuals doing part of the hole
job.

\hfill December 21, 2016

\section{Bat Design on CPU}

In this work the bath algorithm used was the one proposed by
\cite{parpinelli}, since it represents a concrete demonstration of how
the bat metaheuristic given that the original papers lacks it.

The CPU version developed was single threaded.
The random algorithm used was the mersenne twister.

\begin{figure}
\begin{algorithmic}[1]
\State $Parameters:\ n,\alpha,\ \lambda$
\State $initialize\ bats$
\State $evaluate\ fitness$
\State $selects\ best$
\While {$stop\ criteria\ false$}
    \For{$each bat$}

        \State $f_i=f_{min} + (f_{max} - f_{min})\beta, \in \beta [0,1]$
        \State $\vec{v}_i^{t+1} = \vec{v}_i^{t} + (\vec{x}_i^{t} + \vec{x}_*^{t})f_i$
        \State $\vec{x}_{temp} = \vec{x}_i^{t} + \vec{v}_i^{t+1}$
        \If {$rand < r_i, rand \in [0,1] $}


            \State $\vec{x}_{temp} = \vec{x}_* + \epsilon A_m, \epsilon \in [-1, 1]$
        \EndIf

        \State $single\ dimension\ perturbation\ in\ x_{temp}$
        \If {$a < A_i^t , a \in [0,1] $}
            \State $\vec{x}_i^t = \vec{x}_{temp}$
            \State $r_i = exp(\lambda * i)$
            \State $A_i =  A_{0} * \alpha^i$
        \EndIf
        \State $selects\ best$
    \EndFor
\EndWhile
\end{algorithmic}
\caption{Pseudo-code CPU}\label{GPU}
\end{figure}


\section{Bat Design on GPU}

Since the BAT algorithm uses a population of bats, the most intuitive
parallelization method to apply on it is to use each bat on a GPU core.
\cite{pso-gpu} used a similar method for a GPU implementation for the PSO algorithm.
For the GPU version the approach used was the split of each individual in one thread.

The random number generator used on the GPU was the MTGP32, to
maintain the compatibility with the CPU version. Notwithstanding it's
not recommended to use more than 256 threads per block with it
\cite{curandIssue}.

\begin{figure}
\begin{algorithmic}[1]
\State $Parameters:\ n,\alpha,\ \lambda$
\State $initialize\ bats\ asynchronously$
\State $evaluate\ fitness$
\State $synchronize\ threads$
\State $selects\ best$
\While {$stop\ criteria\ false$}
    \For{$each thread$}

        \State $f_i=f_{min} + (f_{max} - f_{min})\beta, \in \beta [0,1]$
        \State $\vec{v}_i^{t+1} = \vec{v}_i^{t} + (\vec{x}_i^{t} + \vec{x}_*^{t})f_i$
        \State $\vec{x}_{temp} = \vec{x}_i^{t} + \vec{v}_i^{t+1}$
        \If {$rand < r_i, rand \in [0,1] $}


            \State $\vec{x}_{temp} = \vec{x}_* + \epsilon A_m, \epsilon \in [-1, 1]$
        \EndIf

        \State $single\ dimension\ perturbation\ in\ x_{temp}$
        \If {$a < A_i^t , a \in [0,1] $}
            \State $\vec{x}_i^t = \vec{x}_{temp}$
            \State $r_i = exp(\lambda * i)$
            \State $A_i =  A_{0} * \alpha^i$
        \EndIf
        \State $synchronize\ threads$
        \State $selects\ best$
    \EndFor
\EndWhile
\end{algorithmic}
\caption{Pseudo-code GPU}\label{GPU}
\end{figure}

\section{Experiments}

For testing the performance of the algorithm a set of experiments where
developed using diverse benchmark functions tested against a set of
individuals in a highly dimensional problem.

The benchmark functions used were the following:

\begin{itemize}
    \item Ackley
    \item Griewank
    \item Rastringin
    \item Rosenbrook
\end{itemize}

The experiments were executed on a machine with the following configuration:

\textit{Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz \\ GK208 GeForce GT 720 1024 MB of vram}

Each experiment was executed a total of 20 times with 10 thousand iterations each and 100 dimensions in each function.

\begin{table}[!htbp]
    \renewcommand{\arraystretch}{1.3}
    \caption{Experiments}
    \label{experiments}
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
        \bf Name & Function &  Dimensions & Agents\\
    \hline
        E1 & Ackley & 100 & 256\\
        E2 & Ackley & 100 & 768\\
        E3 & Griewank & 100 & 256\\
        E4 & Griewank & 100 & 768\\
        E5 & Rastringin & 100 & 256\\
        E6 & Rastringin & 100 & 768\\
        E7 & Rosenbrook & 100 & 256\\
        E8 & Rosenbrook & 100 & 768\\
    \end{tabular}
\end{table}

\section{Results}

Below are described the speedup and convergence results. The time spent in each execution of the algorithms is described in seconds.

\begin{table}[!t]
    \renewcommand{\arraystretch}{1.3}
    \caption{Speedup Results}
    \label{results}
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
        \bf Name & Time CPU & Time GPU & Speedup\\
    \hline
        E1 & 57.3774 & ?? & ?? \\
        E3 & 54.6234 & 20.2427 & 2.6984 \\
        E5 & 42.3531 & 32.1898 & 1.3157 \\
        E7 & 24.7752 & 26.4898 & 0.9352 \\
    \end{tabular}
\end{table}

\begin{table}[!t]
    \renewcommand{\arraystretch}{1.3}
    \caption{Convergence Results}
    \label{results}
    \centering
    \begin{tabular}{c|c|c}
    \hline
        \bf Name & Fitness CPU & Fitness GPU \\
    \hline
        E1 & 1.69691e-06 & ?? \\
        E3 & 8.34383e-13 &  2.0095e-15  \\
        E3 & 6.50132e-07 & 0 \\
        E7 & 93.884 & 96.7034 & \\
    \end{tabular}
\end{table}

\section{Conclusion}

It was observed speedups with big populations. The original BAT was
proposed with 40 individuals and the speedups was seen with 250
individuals.
The advantages of the algorithm may be tested against a threaded CPU implementation to be fair.

With this work it's clear that is possible to speedup the bat metaheuristic using GPU. Notwithstanding the best results are only achievable on really complex problems with many dimensions.

\section{Further works}

In the future it may be explored the usage of blocks as representation for the
dimensions in which each bat details.

A subpopulation approach may also work, considering each GPU block as it's boundaries, somewhat similar to the work made on parallel bat on CPU by FU \cite{paralellCPU}.

\begin{thebibliography}{1}

\bibitem{original}
    Xin-She Yang \emph{A New Metaheuristics Bat-Inspired Algorithm}. Department of Engineering, Cambridge, 2010.
\bibitem{parpinelli}
    Jelson A. Cordeiro, Rafael Stubs Parpinelli Heitor Silvério Lopes \emph{Análise de Sensibilidade dos Parâmetros do Bat Algorithm e Comparação de Desempenho}.
\bibitem{pso-gpu}
    PSO-GPU: Accelerating Particle Swarm Optimization in CUDA-Based Graphics Processing Unit
\bibitem{curandIssue}
    \url{http://docs.nvidia.com/cuda/curand/device-api-overview.html#device-api-overview}
\bibitem{paralellCPU}
    Parallelized Bat Algorithm with a Communication Strategy. Cheng-Fu Tsai, Thin-Kien Dao, Wei-Jie Yang, et al, University of applied sciences

\bibitem{paralellCPUFirst}
    Parallel bat algorithm for optimizing makespan in job scheduling problems, Thi-Kien Dao, Tien-Szu Pan, Trong-The Nguyen, Jeng-Shyang Pan,2015, Springer Sience Review

\end{thebibliography}

\end{document}
