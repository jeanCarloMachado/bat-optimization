\documentclass[conference]{IEEEtran}

\usepackage[fleqn]{amsmath}
\usepackage{algpseudocode}
\interdisplaylinepenalty=2500
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
\title{Parallel Bat Optimization on GPU using CUDA}

\author{\IEEEauthorblockN{Jean Carlo Machado}
\IEEEauthorblockA{Univerisdade do Estado de Santa Catarina\\Mestrado de Computação Aplicada\\
UDESC\\
Santa Catarina, Joinville,\\
Email: contato@jeancarlomachado.com.br}
\and
\IEEEauthorblockN{Rafael Stubs Parpinelli}
\IEEEauthorblockA{Univerisdade do Estado de Santa Catarina\\ UDESC\\
Santa Catarina, Joinville
}}

\maketitle
\begin{abstract}
The ever increasing parallel processing power of GP's is an attractive
motive to implement optimization algorithms on this platform. This work
aimed to develop a GPU version of the bat metaheuristic, a CPU version
were developed as well, as a way of comparison. A set of experiments where
made in order to measure the speedup. The research shows that the GPU
version is able to achieve relevant speedups in highly populational
problems but for simpler cases the CPU version might outperform GPU.
\end{abstract}
\IEEEpeerreviewmaketitle

\section{Introduction}

The bat algorithm is a populational meta-heuristic introduced by Yang in
2010. It uses the inspiration of micro-bats which uses a type of sonar,
called echolocation, to detect prey, avoid obstacles, and locate their
roosting crevices in the dark \cite{original}.

All populational meta-heuristic theoretically can benefit from implicit
parallelization, which is the approach that each individual of the
populations executes concurrently. The GPU is a great place to run populational algorithms because GPUs are able to
parallelize high loads of concurrent individuals doing part of the hole
job.
For highly parallel general processing application, speedups may vary from 10 to 450 \cite{cuda_optimizations}.


This work attempts to investigate the applicability of the BAT algorithm
concurrently on the GPU. Previously some demonstrations of the bat
algorithm parallelized on CPU were presented in \cite{paralellCPUFirst}
and \cite{paralellCPU}, however, til the day of this publication no
implementation of the bat algorithm was found for GPU. 

\section{The CUDA platform}

The CUDA platform uses a parallelization schema in "each cuda device supports the Single-Program Multiple-Data (SPMD)" \cite{cuda_optimizations}, where all concurrent threads are based on the same code but they may follow different paths.


A good approach is to use the threaded model since it has the great benefit in performance.


"..when attempting to achieve an application's maximum
performance, the primary concern often is managing global memory
latency." \cite{cuda_optimizations}

\section{Bat Design on CPU}

In this work the bath algorithm used was the one proposed by
\autocite{jelson}, since it represents a concrete demonstration of how
the bat metaheuristic given that the original paper dont show clearly the expected behavior of the algorithm.

Some distinctions of the original paper are worth noticing.

- The selection of new results on the original paper tends to be more greedy (line 14).
On this paper the or operator were used but in the original one an And were proposed.
The or operator tends to explore the search space better (more diversity).

- There's a distortion on a single dimension of the search space in order to increase the diversity factor.

The CPU version developed was single threaded.
The random algorithm used was the Mersenne twister.

\begin{figure}
\begin{algorithmic}[1]
\State $Parameters:\ n,\alpha,\ \lambda$
\State $initialize\ bats$
\State $evaluate\ fitness$
\State $selects\ best$
\While {$stop\ criteria\ false$}
    \For{$each\ bat$}

        \State $f_i=f_{min} + (f_{max} - f_{min})\beta, \in \beta [0,1]$
        \State $\vec{v}_i^{t+1} = \vec{v}_i^{t} + (\vec{x}_i^{t} + \vec{x}_*^{t})f_i$
        \State $\vec{x}_{temp} = \vec{x}_i^{t} + \vec{v}_i^{t+1}$
        \If {$rand < r_i, rand \in [0,1] $}


            \State $\vec{x}_{temp} = \vec{x}_* + \epsilon A_m, \epsilon \in [-1, 1]$
        \EndIf

        \State $single\ dimension\ perturbation\ in\ x_{temp}$
        \If {$a < A_i^t\ \textbf{or}\ f(\vec{x}_{temp}) \leq f(\vec{x}_i), a \in [0,1] $}
            \State $\vec{x}_i^t = \vec{x}_{temp}$
            \State $r_i = exp(\lambda * i)$
            \State $A_i =  A_{0} * \alpha^i$
        \EndIf
        \State $selects\ best$
    \EndFor
\EndWhile
\end{algorithmic}
\caption{Pseudo-code CPU}\label{GPU}
\end{figure}


\section{Bat Design on GPU}

Since the BAT algorithm uses a population of bats, the most intuitive
parallelization method to apply on it is to use each bat on a GPU core.
\cite{pso-gpu} used a similar method for a GPU implementation for the PSO algorithm.
For the GPU version the approach used was the split of each individual in one thread.

In the bat algorithm synchronization must occur on the selection of the best individual of the iteration. The best individual is kept in the threaded memory of the GPU which has a limit of 16KB, not feasible for the most complex problems.

The random number generator used on the GPU was the MTGP32, to
maintain the compatibility with the CPU version. Notwithstanding it's
not recommended to use more than 256 threads per block with it
\cite{curandIssue}.

\begin{figure}
\begin{algorithmic}[1]
\State $Parameters:\ n,\alpha,\ \lambda$
\State $initialize\ bats\ asynchronously$
\State $evaluate\ fitness$
\State $synchronize\ threads$
\State $selects\ best$
\While {$stop\ criteria\ false$}
    \For{$each thread$}

        \State $f_i=f_{min} + (f_{max} - f_{min})\beta, \in \beta [0,1]$
        \State $\vec{v}_i^{t+1} = \vec{v}_i^{t} + (\vec{x}_i^{t} + \vec{x}_*^{t})f_i$
        \State $\vec{x}_{temp} = \vec{x}_i^{t} + \vec{v}_i^{t+1}$
        \If {$rand < r_i, rand \in [0,1] $}


            \State $\vec{x}_{temp} = \vec{x}_* + \epsilon A_m, \epsilon \in [-1, 1]$
        \EndIf

        \State $single\ dimension\ perturbation\ in\ x_{temp}$
        \If {$a < A_i^t\ \textbf{or}\ f(\vec{x}_{temp}) \leq f(\vec{x}_i), a \in [0,1] $}
            \State $\vec{x}_i^t = \vec{x}_{temp}$
            \State $r_i = exp(\lambda * i)$
            \State $A_i =  A_{0} * \alpha^i$
        \EndIf
        \State $synchronize\ threads$
        \State $selects\ best$
    \EndFor
\EndWhile
\end{algorithmic}
\caption{Pseudo-code GPU}\label{GPU}
\end{figure}

\section{Experiments}

For testing the performance of the algorithm a set of experiments where
developed using diverse benchmark functions tested against a set of
individuals in a highly dimensional problem.

The benchmark functions used were the following:

\begin{itemize}
    \item Ackley
    \item Griewank
    \item Rastringin
    \item Rosenbrook
\end{itemize}

The experiments were executed on a machine with the following configuration:

\textit{Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz \\ GK208 GeForce GT 720 1024 MB of vram}

Each experiment was executed a total of 20 times with 10 thousand iterations each and 100 dimensions in each function.

\begin{table}[!htbp]
    \renewcommand{\arraystretch}{1.3}
    \caption{Experiments}
    \label{experiments}
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
        \bf Name & Function &  Dimensions & Agents\\
    \hline
        E1 & Ackley & 100 & 256\\
        E2 & Ackley & 100 & 768\\
        E3 & Griewank & 100 & 256\\
        E4 & Griewank & 100 & 768\\
        E5 & Rastringin & 100 & 256\\
        E6 & Rastringin & 100 & 768\\
        E7 & Rosenbrook & 100 & 256\\
        E8 & Rosenbrook & 100 & 768\\
    \end{tabular}
\end{table}

\section{Results}

Below are described the speedup and convergence results. The time spent
in each execution of the algorithms is described in seconds.

\begin{table}[!t]
    \renewcommand{\arraystretch}{1.3}
    \caption{Speedup Results}
    \label{results}
    \centering
    \begin{tabular}{c|c|c|c}
    \hline
        \bf Name & Time CPU & Time GPU & Speedup\\
    \hline
        E1 & 57.3774 & ?? & ?? \\
        E3 & 54.6234 & 20.2427 & 2.6984 \\
        E5 & 42.3531 & 32.1898 & 1.3157 \\
        E7 & 24.7752 & 26.4898 & 0.9352 \\
    \end{tabular}
\end{table}

\begin{table}[!t]
    \renewcommand{\arraystretch}{1.3}
    \caption{Convergence Results}
    \label{results}
    \centering
    \begin{tabular}{c|c|c}
    \hline
        \bf Name & Fitness CPU & Fitness GPU \\
    \hline
        E1 & 1.69691e-06 & ?? \\
        E3 & 8.34383e-13 &  2.0095e-15  \\
        E5 & 6.50132e-07 & 0 \\
        E7 & 93.884 & 96.7034 & \\
    \end{tabular}
\end{table}

Rosenbrook function had the poorest speedups in relation with the CPU version, this is probably because this function has much float point operations in relation to the others.

The convergence results of the Rosenbrook function are specially worse than the others but it seems to be a problem with the algorithm since it misbehaves equally bad on CPU.

\section{Conclusion}

It was observed speedups with big populations. The original BAT was
proposed with 40 individuals and the speedups was seen with 250
individuals.
The advantages of the algorithm may be tested against a threaded CPU implementation to be fair.

With this work it's clear that is possible to speedup the bat metaheuristic using GPU. Notwithstanding the best results are only achievable on really complex problems with many dimensions.

\section{Further works}

In the future it may be explored the usage of blocks as representation for the
dimensions in which each bat details.

A subpopulation approach may also work, considering each GPU block as it's boundaries, somewhat similar to the work made on parallel bat on CPU by FU \cite{paralellCPU}.

\begin{thebibliography}{1}

\bibitem{original}
    Xin-She Yang \emph{A New Metaheuristics Bat-Inspired Algorithm}. Department of Engineering, Cambridge, 2010.
\bibitem{jelson}
    Jelson A. Cordeiro, Rafael Stubs Parpinelli Heitor Silvério Lopes \emph{Análise de Sensibilidade dos Parâmetros do Bat Algorithm e Comparação de Desempenho}.
\bibitem{pso-gpu}
    PSO-GPU: Accelerating Particle Swarm Optimization in CUDA-Based Graphics Processing Unit
\bibitem{curandIssue}
    \url{http://docs.nvidia.com/cuda/curand/device-api-overview.html#device-api-overview}
\bibitem{paralellCPU}
    Parallelized Bat Algorithm with a Communication Strategy. Cheng-Fu Tsai, Thin-Kien Dao, Wei-Jie Yang, et al, University of applied sciences

\bibitem{paralellCPUFirst}
    Parallel bat algorithm for optimizing makespan in job scheduling problems, Thi-Kien Dao, Tien-Szu Pan, Trong-The Nguyen, Jeng-Shyang Pan,2015, Springer Sience Review
\bibitem{gpuOptimization}
    Optimization Principles and Application Performance Evaluation of a Multithreaded GPU using Cuda, Shane Ryo
\bibitem{cuda_optimizations}
    Optimization Principles and Application Performance Evaluation on a Multithreaded GPU using CUDA, Shane Ryoo, Critopher I Rodrigues et all

\end{thebibliography}
\end{document}
